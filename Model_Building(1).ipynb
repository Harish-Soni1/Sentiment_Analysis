{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported Necessary Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score,classification_report,confusion_matrix,roc_curve, roc_auc_score,auc\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xg\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Head\n",
      "                                               Review    Label\n",
      "0  may sound noisi initi find good place bar nois...  Postive\n",
      "1  good burger atmospher uniqu expect hard rock m...  Postive\n",
      "2  pre arrang breakfast peopl open us normal open...  Postive\n",
      "3  nice decor share platter crumb chicken spring ...  Postive\n",
      "4  great hard rock never bad countri favourit far...  Postive\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Head\\n\",data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Describe\n",
      "                                                    Review    Label\n",
      "count                                                3062     3062\n",
      "unique                                               1543        3\n",
      "top     visit son whilst break birthday price reason c...  Postive\n",
      "freq                                                    3     2742\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Describe\\n\", data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape\n",
      " (3062, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Shape\\n\",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Label Count\n",
      "\n",
      " Postive     2742\n",
      "Negative     173\n",
      "Neutral      147\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Label Count\\n\\n\", data[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.Label)\n",
    "plt.title(\"Checking Data is balanced or Not, using hist\",fontweight =\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### There is a data imbalance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer\n",
    "\n",
    "#### The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary. You can use it as follows: Create an instance of the CountVectorizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(max_features = 3000)\n",
    "x = count_vect.fit_transform(data['Review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_vector shape\n",
      "\n",
      " (3062, 2424)\n"
     ]
    }
   ],
   "source": [
    "print(\"count_vector shape\\n\\n\",x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE - Synthetic Minority Oversampling Technique\n",
    "\n",
    "##### way to solve this problem is to oversample the examples in the minority class. This can be achieved by simply duplicating examples from the minority class in the training dataset prior to fitting a model. This can balance the class distribution but does not provide any additional information to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sample = SMOTE(random_state = 42, sampling_strategy = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oversample, y_train_oversample = over_sample.fit_sample(x,data['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_Train over sample \n",
      "\n",
      " Neutral     2742\n",
      "Postive     2742\n",
      "Negative    2742\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"y_Train over sample \\n\\n\", y_train_oversample.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train over sample (8226, 2424)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train over sample\", X_train_oversample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['lime'] \n",
    "  \n",
    "plt.hist(y_train_oversample, \n",
    "         density = True,  \n",
    "         histtype ='barstacked', \n",
    "         color = colors)  \n",
    "  \n",
    "plt.title('balanced Data\\n\\n', \n",
    "          fontweight =\"bold\") \n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting The data into Train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X_train_oversample, y_train_oversample, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape= (5758, 2424) \n",
      " y_train shape= (5758,)\n",
      "x_test shape= (2468, 2424) \n",
      " Y_test shape= (2468,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape=\",x_train.shape,'\\n',\"y_train shape=\",y_train.shape)\n",
    "print(\"x_test shape=\",x_test.shape,'\\n',\"Y_test shape=\" ,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble \n",
    "\n",
    "\n",
    "#### Random_Forest_bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=120, n_jobs=-1, random_state=50)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators = 120,\n",
    "                           random_state = 50,\n",
    "                           n_jobs = -1,\n",
    "                           max_features = 'auto')\n",
    "RF.fit(X_train_oversample,y_train_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = RF.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall= 0.9918962722852512 \n",
      "\n",
      "Accuracy of Random forest classifier= 0.9918962722852512 \n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.99      0.98      0.99       804\n",
      "     Neutral       0.98      0.99      0.99       821\n",
      "     Postive       1.00      1.00      1.00       843\n",
      "\n",
      "    accuracy                           0.99      2468\n",
      "   macro avg       0.99      0.99      0.99      2468\n",
      "weighted avg       0.99      0.99      0.99      2468\n",
      " \n",
      "\n",
      "Confusion Matrix \n",
      " [[790  14   0]\n",
      " [  6 815   0]\n",
      " [  0   0 843]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall=\",recall_score(y_test, rf_pred, average='micro'),'\\n')\n",
    "print(\"Accuracy of Random forest classifier=\", accuracy_score(y_test,rf_pred),'\\n')\n",
    "print(\"Classification Report:\\n\", classification_report(y_test,rf_pred),'\\n')\n",
    "print(\"Confusion Matrix \\n\", confusion_matrix(y_test,rf_pred),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultinomialNB Algorithm\n",
    "#### Naive Bayes classifier for multinomial models\n",
    "\n",
    "#### The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn = MultinomialNB()\n",
    "mn.fit(X_train_oversample, y_train_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_pred = mn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall= 0.8727714748784441 \n",
      "\n",
      "Accuracy of Multinomial Naive Bayes= 0.8727714748784441 \n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.79      0.90      0.84       804\n",
      "     Neutral       0.89      0.75      0.81       821\n",
      "     Postive       0.95      0.97      0.96       843\n",
      "\n",
      "    accuracy                           0.87      2468\n",
      "   macro avg       0.88      0.87      0.87      2468\n",
      "weighted avg       0.88      0.87      0.87      2468\n",
      "\n",
      "confusion matrix:\n",
      " [[724  59  21]\n",
      " [184 615  22]\n",
      " [ 10  18 815]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall=\",recall_score(y_test, mn_pred, average='micro'),'\\n')\n",
    "print(\"Accuracy of Multinomial Naive Bayes=\", accuracy_score(y_test,mn_pred),'\\n')\n",
    "print(\"Classification Report:\\n\", classification_report(y_test,mn_pred))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test,mn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(alpha = 0.00047, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.fit(X_train_oversample, y_train_oversample)\n",
    "sgd_pred = sgd.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9671799027552674 \n",
      "\n",
      "Accuracy of SGD= 0.9671799027552674 \n",
      "\n",
      "classification report of SGD:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.98      0.94      0.96       804\n",
      "     Neutral       0.94      0.96      0.95       821\n",
      "     Postive       0.99      1.00      0.99       843\n",
      "\n",
      "    accuracy                           0.97      2468\n",
      "   macro avg       0.97      0.97      0.97      2468\n",
      "weighted avg       0.97      0.97      0.97      2468\n",
      "\n",
      "Confusion matrix sgd:\n",
      " [[753  51   0]\n",
      " [ 19 791  11]\n",
      " [  0   0 843]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall:\",recall_score(y_test,sgd_pred, average = 'micro'),'\\n')\n",
    "print(\"Accuracy of SGD=\", accuracy_score(y_test,sgd_pred),'\\n')\n",
    "print(\"classification report of SGD:\\n\", classification_report(y_test,sgd_pred))\n",
    "print(\"Confusion matrix sgd:\\n\", confusion_matrix(y_test,sgd_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='ovr', random_state=42,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(solver = 'liblinear',\n",
    "                       multi_class = 'ovr',\n",
    "                       max_iter = 1000,\n",
    "                       random_state = 42,\n",
    "                       penalty =\"l2\")\n",
    "LR.fit(X_train_oversample,y_train_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_pred = LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9740680713128039 \n",
      "\n",
      "Accuracy of Logistic Regression= 0.9740680713128039 \n",
      "\n",
      "classification report of Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.95      0.96       804\n",
      "     Neutral       0.95      0.98      0.96       821\n",
      "     Postive       1.00      1.00      1.00       843\n",
      "\n",
      "    accuracy                           0.97      2468\n",
      "   macro avg       0.97      0.97      0.97      2468\n",
      "weighted avg       0.97      0.97      0.97      2468\n",
      "\n",
      "Confusion matrix Logistic Regression:\n",
      " [[762  42   0]\n",
      " [ 20 801   0]\n",
      " [  0   2 841]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall:\",recall_score(y_test,LR_pred, average = 'micro'),'\\n')\n",
    "print(\"Accuracy of Logistic Regression=\", accuracy_score(y_test,LR_pred),'\\n')\n",
    "print(\"classification report of Logistic Regression:\\n\", classification_report(y_test,LR_pred))\n",
    "print(\"Confusion matrix Logistic Regression:\\n\", confusion_matrix(y_test,LR_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:42:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=1, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_class=3, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0.3,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = xg.XGBClassifier(learning_rate = 0.01,\n",
    "                       colsample_bytree = 0.8,\n",
    "                       subsample = 0.8,\n",
    "                       objective = 'multi:softmax', \n",
    "                       n_estimators = 100, \n",
    "                       reg_alpha = 0.3,\n",
    "                       max_depth = 4, \n",
    "                       gamma = 1,\n",
    "                       num_class = 3)\n",
    "xgb.fit(X_train_oversample,y_train_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall= 0.7965964343598055 \n",
      "\n",
      "Accuracy of XGB = 0.7965964343598055 \n",
      "\n",
      "Classification of XGB:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.62      0.73       804\n",
      "     Neutral       0.66      0.94      0.77       821\n",
      "     Postive       0.95      0.83      0.89       843\n",
      "\n",
      "    accuracy                           0.80      2468\n",
      "   macro avg       0.83      0.80      0.80      2468\n",
      "weighted avg       0.83      0.80      0.80      2468\n",
      " \n",
      "\n",
      "Confusion matrix of XGB:\n",
      " [[495 304   5]\n",
      " [ 20 769  32]\n",
      " [ 45  96 702]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall=\",recall_score(y_test,xgb_pred,average = \"micro\"),'\\n')\n",
    "print(\"Accuracy of XGB =\", accuracy_score(y_test,xgb_pred),\"\\n\")\n",
    "print(\"Classification of XGB:\\n\",classification_report(y_test,xgb_pred),\"\\n\")\n",
    "print(\"Confusion matrix of XGB:\\n\",confusion_matrix(y_test,xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# suport vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = svm.LinearSVC(multi_class = 'ovr')\n",
    "svm.fit(X_train_oversample,y_train_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall= 0.983387358184765 \n",
      "\n",
      "Accuracy of svm= 0.983387358184765 \n",
      "\n",
      "Classification of svm:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.98      0.97       804\n",
      "     Neutral       0.98      0.97      0.98       821\n",
      "     Postive       1.00      1.00      1.00       843\n",
      "\n",
      "    accuracy                           0.98      2468\n",
      "   macro avg       0.98      0.98      0.98      2468\n",
      "weighted avg       0.98      0.98      0.98      2468\n",
      "\n",
      "Confusion matrix of svm:\n",
      " [[784  20   0]\n",
      " [ 21 800   0]\n",
      " [  0   0 843]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall=\",recall_score(y_test,svm_pred,average ='micro'),'\\n')\n",
    "print(\"Accuracy of svm=\", accuracy_score(y_test,svm_pred),\"\\n\")\n",
    "print(\"Classification of svm:\\n\",classification_report(y_test,svm_pred))\n",
    "print(\"Confusion matrix of svm:\\n\",confusion_matrix(y_test,svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneVsRestClassifier\n",
    "##### Also known as one-vs-all, this strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only n_classes classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and one classifier only, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy for multiclass classification and is a fair default choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier\n",
    "#### It is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=AdaBoostClassifier())"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_model = OneVsRestClassifier(AdaBoostClassifier())\n",
    "ada_model.fit(X_train_oversample,y_train_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pred = ada_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 0.88290113452188\n",
      "Accuracy of ada = 0.88290113452188 \n",
      "\n",
      "Classification of ada:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.80      0.85       804\n",
      "     Neutral       0.80      0.93      0.86       821\n",
      "     Postive       0.95      0.92      0.93       843\n",
      "\n",
      "    accuracy                           0.88      2468\n",
      "   macro avg       0.89      0.88      0.88      2468\n",
      "weighted avg       0.89      0.88      0.88      2468\n",
      " \n",
      "\n",
      "Confusion matrix of ada:\n",
      " [[642 149  13]\n",
      " [ 30 760  31]\n",
      " [ 30  36 777]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall =\",recall_score(y_test,ada_pred,average='micro'))\n",
    "print(\"Accuracy of ada =\", accuracy_score(y_test,ada_pred),\"\\n\")\n",
    "print(\"Classification of ada:\\n\",classification_report(y_test,ada_pred),\"\\n\")\n",
    "print(\"Confusion matrix of ada:\\n\",confusion_matrix(y_test,ada_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneVsRestClassifier and XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:46:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:47:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:48:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr_model = OneVsRestClassifier(xg.XGBClassifier())\n",
    "ovr_model.fit(X_train_oversample,y_train_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_model_pred = ovr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall= 0.9866288492706645\n",
      "Accuracy of OneVsRestClassifier using xgb= 0.9866288492706645 \n",
      "\n",
      "Classification of  OneVsRestClassifier using xgb:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.99      0.97      0.98       804\n",
      "     Neutral       0.97      0.99      0.98       821\n",
      "     Postive       1.00      1.00      1.00       843\n",
      "\n",
      "    accuracy                           0.99      2468\n",
      "   macro avg       0.99      0.99      0.99      2468\n",
      "weighted avg       0.99      0.99      0.99      2468\n",
      " \n",
      "\n",
      "Confusion matrix of  OneVsRestClassifier using xgb:\n",
      " [[777  27   0]\n",
      " [  5 816   0]\n",
      " [  0   1 842]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall=\",recall_score(y_test,ovr_model_pred, average='micro'))\n",
    "print(\"Accuracy of OneVsRestClassifier using xgb=\", accuracy_score(y_test,ovr_model_pred),\"\\n\")\n",
    "print(\"Classification of  OneVsRestClassifier using xgb:\\n\",classification_report(y_test,ovr_model_pred),\"\\n\")\n",
    "print(\"Confusion matrix of  OneVsRestClassifier using xgb:\\n\",confusion_matrix(y_test,ovr_model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 2)\n",
    "knn.fit(X_train_oversample,y_train_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall= 0.9351701782820098\n",
      "Accuracy of knn= 0.9351701782820098 \n",
      "\n",
      "Classification of  knn:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.83      1.00      0.91       804\n",
      "     Neutral       1.00      0.81      0.89       821\n",
      "     Postive       1.00      1.00      1.00       843\n",
      "\n",
      "    accuracy                           0.94      2468\n",
      "   macro avg       0.94      0.94      0.93      2468\n",
      "weighted avg       0.95      0.94      0.93      2468\n",
      " \n",
      "\n",
      "Confusion matrix of knn:\n",
      " [[804   0   0]\n",
      " [158 663   0]\n",
      " [  2   0 841]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall=\",recall_score(y_test,knn_pred,average = 'micro'))\n",
    "print(\"Accuracy of knn=\", accuracy_score(y_test,knn_pred),\"\\n\")\n",
    "print(\"Classification of  knn:\\n\",classification_report(y_test,knn_pred),\"\\n\")\n",
    "print(\"Confusion matrix of knn:\\n\",confusion_matrix(y_test,knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0005, penalty='l1')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = Perceptron(penalty = 'l1',\n",
    "                alpha = 0.0005)\n",
    "per.fit(X_train_oversample, y_train_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_pred = per.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall= 0.8845218800648298\n",
      "Accuracy of  Perceptron= 0.8845218800648298 \n",
      "\n",
      "Classification of   Perceptron:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.96      0.76      0.85       804\n",
      "     Neutral       0.78      0.96      0.86       821\n",
      "     Postive       0.95      0.93      0.94       843\n",
      "\n",
      "    accuracy                           0.88      2468\n",
      "   macro avg       0.90      0.88      0.88      2468\n",
      "weighted avg       0.90      0.88      0.88      2468\n",
      " \n",
      "\n",
      "Confusion matrix of  Perceptron:\n",
      " [[611 174  19]\n",
      " [  6 791  24]\n",
      " [ 18  44 781]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall=\",recall_score(y_test,per_pred,average='micro'))\n",
    "print(\"Accuracy of  Perceptron=\", accuracy_score(y_test,per_pred),\"\\n\")\n",
    "print(\"Classification of   Perceptron:\\n\",classification_report(y_test,per_pred),\"\\n\")\n",
    "print(\"Confusion matrix of  Perceptron:\\n\",confusion_matrix(y_test,per_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(class_weight = 'balanced',\n",
    "                                 C = 0.4)\n",
    "pac.fit(X_train_oversample, y_train_oversample)\n",
    "pac_pred = pac.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall= 0.9817666126418152\n",
      "Accuracy of  PassiveAggressiveClassifier= 0.9817666126418152 \n",
      "\n",
      "Classification of   PassiveAggressiveClassifier\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.98      0.97       804\n",
      "     Neutral       0.98      0.97      0.97       821\n",
      "     Postive       1.00      1.00      1.00       843\n",
      "\n",
      "    accuracy                           0.98      2468\n",
      "   macro avg       0.98      0.98      0.98      2468\n",
      "weighted avg       0.98      0.98      0.98      2468\n",
      " \n",
      "\n",
      "Confusion matrix of  PassiveAggressiveClassifier\n",
      "\n",
      "\n",
      " [[787  17   0]\n",
      " [ 28 793   0]\n",
      " [  0   0 843]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall=\", recall_score(y_test,pac_pred,average='micro'))\n",
    "print(\"Accuracy of  PassiveAggressiveClassifier=\", accuracy_score(y_test,pac_pred),\"\\n\")\n",
    "print(\"Classification of   PassiveAggressiveClassifier\\n\\n\",classification_report(y_test,pac_pred),\"\\n\")\n",
    "print(\"Confusion matrix of  PassiveAggressiveClassifier\\n\\n\\n\",confusion_matrix(y_test,pac_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train_oversample, y_train_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pred = lda.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall= 0.9712317666126418\n",
      "Accuracy of  LinearDiscriminantAnalysi= 0.9712317666126418 \n",
      "\n",
      "Classification of   LinearDiscriminantAnalysi\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.98      0.93      0.96       804\n",
      "     Neutral       0.93      0.98      0.96       821\n",
      "     Postive       1.00      1.00      1.00       843\n",
      "\n",
      "    accuracy                           0.97      2468\n",
      "   macro avg       0.97      0.97      0.97      2468\n",
      "weighted avg       0.97      0.97      0.97      2468\n",
      " \n",
      "\n",
      "Confusion matrix of  LinearDiscriminantAnalysi\n",
      "\n",
      "\n",
      " [[747  57   0]\n",
      " [ 13 808   0]\n",
      " [  0   1 842]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall=\",recall_score(y_test,lda_pred,average='micro'))\n",
    "print(\"Accuracy of  LinearDiscriminantAnalysi=\", accuracy_score(y_test,lda_pred),\"\\n\")\n",
    "print(\"Classification of   LinearDiscriminantAnalysi\\n\\n\",classification_report(y_test,lda_pred),\"\\n\")\n",
    "print(\"Confusion matrix of  LinearDiscriminantAnalysi\\n\\n\\n\",confusion_matrix(y_test,lda_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIDGE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc = RidgeClassifier()\n",
    "rc.fit(X_train_oversample, y_train_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_pred = rc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall= 0.9517828200972447 \n",
      "\n",
      "Accuracy of ridge= 0.9517828200972447 \n",
      "\n",
      "Classification of ridge:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.88      0.92       804\n",
      "     Neutral       0.89      0.97      0.93       821\n",
      "     Postive       1.00      1.00      1.00       843\n",
      "\n",
      "    accuracy                           0.95      2468\n",
      "   macro avg       0.95      0.95      0.95      2468\n",
      "weighted avg       0.95      0.95      0.95      2468\n",
      " \n",
      "\n",
      "Confusion matrix of ridge:\n",
      " [[707  97   0]\n",
      " [ 21 800   0]\n",
      " [  1   0 842]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall=\",recall_score(y_test,rc_pred,average='micro'),'\\n')\n",
    "print(\"Accuracy of ridge=\", accuracy_score(y_test,rc_pred),\"\\n\")\n",
    "print(\"Classification of ridge:\\n\",classification_report(y_test,rc_pred),\"\\n\")\n",
    "print(\"Confusion matrix of ridge:\\n\",confusion_matrix(y_test,rc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Model Accuracy\n",
      "---------------------------------------------\n",
      "Accuracy of Random forest classifier= 0.9918962722852512 \n",
      "\n",
      "---------------------------------------------\n",
      "Accuracy of Multinomial Naive Bayes= 0.8727714748784441 \n",
      "\n",
      "---------------------------------------------\n",
      "Accuracy of SGD= 0.9671799027552674 \n",
      "\n",
      "---------------------------------------------\n",
      "Accuracy of Logistic Regression= 0.9740680713128039 \n",
      "\n",
      "---------------------------------------------\n",
      "Accuracy of svm= 0.983387358184765 \n",
      "\n",
      "---------------------------------------------\n",
      "Accuracy of ada = 0.88290113452188 \n",
      "\n",
      "---------------------------------------------\n",
      "Accuracy of XGB = 0.7965964343598055 \n",
      "\n",
      "---------------------------------------------\n",
      "Accuracy of knn= 0.9351701782820098 \n",
      "\n",
      "---------------------------------------------\n",
      "Accuracy of Perceptron= 0.8845218800648298 \n",
      "\n",
      "---------------------------------------------\n",
      "Accuracy of PassiveAggressiveClassifier= 0.9817666126418152 \n",
      "\n",
      "---------------------------------------------\n",
      "Accuracy of LinearDiscriminantAnalysi= 0.9712317666126418 \n",
      "\n",
      "---------------------------------------------\n",
      "Accuracy of ridge= 0.9517828200972447 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"All Model Accuracy\")\n",
    "\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Accuracy of Random forest classifier=\", accuracy_score(y_test,rf_pred),'\\n')\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Accuracy of Multinomial Naive Bayes=\", accuracy_score(y_test,mn_pred),'\\n')\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Accuracy of SGD=\", accuracy_score(y_test,sgd_pred),'\\n')\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Accuracy of Logistic Regression=\", accuracy_score(y_test,LR_pred),'\\n')\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Accuracy of svm=\", accuracy_score(y_test,svm_pred),\"\\n\")\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Accuracy of ada =\", accuracy_score(y_test,ada_pred),\"\\n\")\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Accuracy of XGB =\", accuracy_score(y_test,xgb_pred),\"\\n\")\n",
    "print(\"---------------------------------------------\")\n",
    "#print(\"Accuracy of OneVsRestClassifier using xgb=\", accuracy_score(y_test,ovr_model_pred),\"\\n\")\n",
    "print(\"Accuracy of knn=\", accuracy_score(y_test,knn_pred),\"\\n\")\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Accuracy of Perceptron=\", accuracy_score(y_test,per_pred),\"\\n\")\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Accuracy of PassiveAggressiveClassifier=\", accuracy_score(y_test,pac_pred),\"\\n\")\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Accuracy of LinearDiscriminantAnalysi=\", accuracy_score(y_test,lda_pred),\"\\n\")\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Accuracy of ridge=\", accuracy_score(y_test,rc_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We selected RandomForest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
